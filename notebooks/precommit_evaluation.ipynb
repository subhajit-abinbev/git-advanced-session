{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614f5195",
   "metadata": {},
   "source": [
    "# Pre-Commit Configuration Evaluation\n",
    "\n",
    "This notebook provides a comprehensive evaluation of the `.pre-commit-config.yaml` file, focusing on:\n",
    "- üìä **File Size Checks** - Preventing large file commits\n",
    "- üîê **Secret Detection** - Multiple layers of security scanning\n",
    "- üìì **Notebook Stripouts** - Jupyter notebook cleaning\n",
    "- ‚öôÔ∏è **Configuration Analysis** - Best practices and recommendations\n",
    "\n",
    "## Evaluation Criteria\n",
    "- ‚úÖ **Security**: Does it prevent sensitive data leaks?\n",
    "- ‚úÖ **Performance**: Are the hooks efficient and fast?\n",
    "- ‚úÖ **Maintainability**: Is the configuration easy to maintain?\n",
    "- ‚úÖ **Completeness**: Does it cover all necessary checks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429df73a",
   "metadata": {},
   "source": [
    "## 1. Load and Parse the YAML Configuration\n",
    "\n",
    "First, let's load the pre-commit configuration file and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c8512",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.11.13)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n .conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Load the pre-commit configuration\n",
    "config_path = Path(\"../.pre-commit-config.yaml\")\n",
    "\n",
    "try:\n",
    "    with open(config_path, 'r', encoding='utf-8') as file:\n",
    "        precommit_config = yaml.safe_load(file)\n",
    "    \n",
    "    print(\"‚úÖ Successfully loaded .pre-commit-config.yaml\")\n",
    "    print(f\"üìÑ Configuration has {len(precommit_config.get('repos', []))} repository hooks\")\n",
    "    \n",
    "    # Display basic structure\n",
    "    print(\"\\nüìã Configuration Overview:\")\n",
    "    for i, repo in enumerate(precommit_config.get('repos', []), 1):\n",
    "        repo_name = repo['repo'].split('/')[-1] if '/' in repo['repo'] else repo['repo']\n",
    "        hook_count = len(repo.get('hooks', []))\n",
    "        print(f\"  {i}. {repo_name} ({hook_count} hooks)\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå .pre-commit-config.yaml not found!\")\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"‚ùå YAML parsing error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading configuration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf090d",
   "metadata": {},
   "source": [
    "## 2. Analyze File Size Check Configuration\n",
    "\n",
    "Let's examine the `check-added-large-files` hook to evaluate its effectiveness in preventing large file commits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc93973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and analyze file size check configuration\n",
    "file_size_analysis = {\n",
    "    \"found\": False,\n",
    "    \"max_size_kb\": None,\n",
    "    \"max_size_mb\": None,\n",
    "    \"recommendation\": \"‚ùå Not configured\"\n",
    "}\n",
    "\n",
    "for repo in precommit_config.get('repos', []):\n",
    "    for hook in repo.get('hooks', []):\n",
    "        if hook.get('id') == 'check-added-large-files':\n",
    "            file_size_analysis[\"found\"] = True\n",
    "            \n",
    "            # Extract maxkb argument\n",
    "            args = hook.get('args', [])\n",
    "            for arg in args:\n",
    "                if '--maxkb=' in arg:\n",
    "                    kb_value = int(arg.split('=')[1])\n",
    "                    file_size_analysis[\"max_size_kb\"] = kb_value\n",
    "                    file_size_analysis[\"max_size_mb\"] = round(kb_value / 1024, 2)\n",
    "                    break\n",
    "\n",
    "print(\"üìä File Size Check Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if file_size_analysis[\"found\"]:\n",
    "    print(\"‚úÖ check-added-large-files hook is configured\")\n",
    "    \n",
    "    if file_size_analysis[\"max_size_kb\"]:\n",
    "        size_kb = file_size_analysis[\"max_size_kb\"]\n",
    "        size_mb = file_size_analysis[\"max_size_mb\"]\n",
    "        print(f\"üìè Maximum file size: {size_kb} KB ({size_mb} MB)\")\n",
    "        \n",
    "        # Evaluate the size limit\n",
    "        if size_kb <= 500:  # 500KB\n",
    "            print(\"üü¢ Excellent: Very strict size limit prevents almost all large files\")\n",
    "            file_size_analysis[\"recommendation\"] = \"üü¢ Excellent configuration\"\n",
    "        elif size_kb <= 1000:  # 1MB\n",
    "            print(\"üü° Good: Reasonable size limit for most projects\")\n",
    "            file_size_analysis[\"recommendation\"] = \"üü° Good configuration\"\n",
    "        elif size_kb <= 5000:  # 5MB\n",
    "            print(\"üü† Fair: Size limit may allow some large files\")\n",
    "            file_size_analysis[\"recommendation\"] = \"üü† Consider reducing limit\"\n",
    "        else:\n",
    "            print(\"üî¥ Poor: Size limit is too high\")\n",
    "            file_size_analysis[\"recommendation\"] = \"üî¥ Reduce size limit\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Default size limit (no --maxkb specified)\")\n",
    "        file_size_analysis[\"recommendation\"] = \"‚ö†Ô∏è  Add explicit --maxkb argument\"\n",
    "else:\n",
    "    print(\"‚ùå check-added-large-files hook is NOT configured\")\n",
    "    print(\"üö® This is a critical security gap!\")\n",
    "\n",
    "print(f\"\\nüí° Recommendation: {file_size_analysis['recommendation']}\")\n",
    "\n",
    "# Test with current repository files\n",
    "print(f\"\\nüîç Current Repository File Analysis:\")\n",
    "large_files = []\n",
    "for root, dirs, files in os.walk(\"..\"):\n",
    "    # Skip .git directory\n",
    "    if '.git' in root:\n",
    "        continue\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            size_bytes = os.path.getsize(file_path)\n",
    "            size_kb = size_bytes / 1024\n",
    "            \n",
    "            # Check against configured limit or default 1MB\n",
    "            limit_kb = file_size_analysis.get(\"max_size_kb\", 1000)\n",
    "            \n",
    "            if size_kb > limit_kb:\n",
    "                large_files.append({\n",
    "                    \"path\": os.path.relpath(file_path, \"..\"),\n",
    "                    \"size_kb\": round(size_kb, 2),\n",
    "                    \"size_mb\": round(size_kb / 1024, 2)\n",
    "                })\n",
    "        except (OSError, IOError):\n",
    "            continue\n",
    "\n",
    "if large_files:\n",
    "    print(f\"‚ö†Ô∏è  Found {len(large_files)} files exceeding size limit:\")\n",
    "    for file_info in large_files[:5]:  # Show first 5\n",
    "        print(f\"  üìÑ {file_info['path']}: {file_info['size_kb']} KB ({file_info['size_mb']} MB)\")\n",
    "    if len(large_files) > 5:\n",
    "        print(f\"  ... and {len(large_files) - 5} more files\")\n",
    "else:\n",
    "    print(\"‚úÖ No files exceed the configured size limit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be5227",
   "metadata": {},
   "source": [
    "## 3. Evaluate Secret Detection Setup\n",
    "\n",
    "Analyzing the multi-layered secret detection configuration including detect-secrets and GitGuardian shield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8dbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze secret detection configuration\n",
    "secret_detection = {\n",
    "    \"detect_private_key\": False,\n",
    "    \"detect_aws_credentials\": False,\n",
    "    \"detect_secrets\": False,\n",
    "    \"ggshield\": False,\n",
    "    \"baseline_file\": None,\n",
    "    \"exclusions\": [],\n",
    "    \"coverage_score\": 0\n",
    "}\n",
    "\n",
    "print(\"üîê Secret Detection Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for repo in precommit_config.get('repos', []):\n",
    "    for hook in repo.get('hooks', []):\n",
    "        hook_id = hook.get('id')\n",
    "        \n",
    "        # Check for basic secret detection hooks\n",
    "        if hook_id == 'detect-private-key':\n",
    "            secret_detection[\"detect_private_key\"] = True\n",
    "            print(\"‚úÖ detect-private-key: Detects SSH/TLS private keys\")\n",
    "            \n",
    "        elif hook_id == 'detect-aws-credentials':\n",
    "            secret_detection[\"detect_aws_credentials\"] = True\n",
    "            print(\"‚úÖ detect-aws-credentials: Detects AWS credentials\")\n",
    "            \n",
    "        elif hook_id == 'detect-secrets':\n",
    "            secret_detection[\"detect_secrets\"] = True\n",
    "            print(\"‚úÖ detect-secrets: Advanced secret scanning\")\n",
    "            \n",
    "            # Check for baseline file\n",
    "            args = hook.get('args', [])\n",
    "            for arg in args:\n",
    "                if '--baseline' in arg and len(args) > args.index(arg) + 1:\n",
    "                    baseline_file = args[args.index(arg) + 1]\n",
    "                    secret_detection[\"baseline_file\"] = baseline_file\n",
    "                    print(f\"   üìÑ Baseline file: {baseline_file}\")\n",
    "                    \n",
    "                    # Check if baseline file exists\n",
    "                    baseline_path = Path(f\"../{baseline_file}\")\n",
    "                    if baseline_path.exists():\n",
    "                        print(\"   ‚úÖ Baseline file exists\")\n",
    "                    else:\n",
    "                        print(\"   ‚ùå Baseline file missing!\")\n",
    "            \n",
    "            # Check exclusions\n",
    "            exclude = hook.get('exclude')\n",
    "            if exclude:\n",
    "                secret_detection[\"exclusions\"].append(exclude)\n",
    "                print(f\"   üö´ Exclusions: {exclude}\")\n",
    "                \n",
    "        elif hook_id == 'ggshield':\n",
    "            secret_detection[\"ggshield\"] = True\n",
    "            print(\"‚úÖ ggshield: GitGuardian security scanning\")\n",
    "\n",
    "# Calculate coverage score\n",
    "coverage_components = [\n",
    "    secret_detection[\"detect_private_key\"],\n",
    "    secret_detection[\"detect_aws_credentials\"], \n",
    "    secret_detection[\"detect_secrets\"],\n",
    "    secret_detection[\"ggshield\"]\n",
    "]\n",
    "secret_detection[\"coverage_score\"] = sum(coverage_components)\n",
    "\n",
    "print(f\"\\nüìä Secret Detection Coverage Score: {secret_detection['coverage_score']}/4\")\n",
    "\n",
    "if secret_detection[\"coverage_score\"] == 4:\n",
    "    print(\"üü¢ Excellent: Comprehensive multi-layered secret detection\")\n",
    "elif secret_detection[\"coverage_score\"] == 3:\n",
    "    print(\"üü° Good: Strong secret detection with minor gaps\")\n",
    "elif secret_detection[\"coverage_score\"] == 2:\n",
    "    print(\"üü† Fair: Basic secret detection, consider adding more layers\")\n",
    "else:\n",
    "    print(\"üî¥ Poor: Insufficient secret detection coverage\")\n",
    "\n",
    "# Test secret detection with our .env file\n",
    "print(f\"\\nüß™ Testing Secret Detection with .env file:\")\n",
    "env_file_path = Path(\"../.env\")\n",
    "if env_file_path.exists():\n",
    "    print(\"‚úÖ .env file exists (contains fake secrets for testing)\")\n",
    "    \n",
    "    # Check if .env would be caught by gitignore\n",
    "    gitignore_path = Path(\"../.gitignore\") \n",
    "    if gitignore_path.exists():\n",
    "        with open(gitignore_path, 'r') as f:\n",
    "            gitignore_content = f.read()\n",
    "            if '.env' in gitignore_content:\n",
    "                print(\"‚úÖ .env file is properly ignored by .gitignore\")\n",
    "            else:\n",
    "                print(\"‚ùå .env file is NOT in .gitignore!\")\n",
    "    \n",
    "    # Sample some content to show what would be detected\n",
    "    with open(env_file_path, 'r') as f:\n",
    "        env_content = f.read()\n",
    "        \n",
    "    # Count potential secrets\n",
    "    api_key_patterns = [\n",
    "        r'API_KEY\\s*=\\s*[^\\s]+',\n",
    "        r'SECRET\\s*=\\s*[^\\s]+', \n",
    "        r'TOKEN\\s*=\\s*[^\\s]+',\n",
    "        r'PASSWORD\\s*=\\s*[^\\s]+'\n",
    "    ]\n",
    "    \n",
    "    total_secrets = 0\n",
    "    for pattern in api_key_patterns:\n",
    "        matches = re.findall(pattern, env_content, re.IGNORECASE)\n",
    "        total_secrets += len(matches)\n",
    "    \n",
    "    print(f\"üéØ Found {total_secrets} potential secrets in .env file\")\n",
    "    print(\"   These would be caught by secret detection hooks if not properly ignored\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå .env file not found for testing\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "if not secret_detection[\"detect_secrets\"]:\n",
    "    print(\"   üî∏ Add detect-secrets for comprehensive scanning\")\n",
    "if not secret_detection[\"ggshield\"]:\n",
    "    print(\"   üî∏ Add ggshield for GitGuardian integration\")\n",
    "if secret_detection[\"baseline_file\"] and not Path(f\"../{secret_detection['baseline_file']}\").exists():\n",
    "    print(\"   üî∏ Create the missing baseline file\")\n",
    "if secret_detection[\"coverage_score\"] == 4:\n",
    "    print(\"   üü¢ Secret detection configuration is excellent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f911663",
   "metadata": {},
   "source": [
    "## 4. Review Notebook Stripout Configuration\n",
    "\n",
    "Examining the nbstripout hook that cleans Jupyter notebooks before committing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb205dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze notebook stripout configuration\n",
    "notebook_config = {\n",
    "    \"nbstripout_found\": False,\n",
    "    \"repo_info\": None,\n",
    "    \"version\": None,\n",
    "    \"notebook_count\": 0,\n",
    "    \"notebooks_with_outputs\": []\n",
    "}\n",
    "\n",
    "print(\"üìì Notebook Stripout Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check for nbstripout configuration\n",
    "for repo in precommit_config.get('repos', []):\n",
    "    for hook in repo.get('hooks', []):\n",
    "        if hook.get('id') == 'nbstripout':\n",
    "            notebook_config[\"nbstripout_found\"] = True\n",
    "            notebook_config[\"repo_info\"] = repo['repo']\n",
    "            notebook_config[\"version\"] = repo.get('rev', 'Unknown')\n",
    "            print(\"‚úÖ nbstripout hook is configured\")\n",
    "            print(f\"   üì¶ Repository: {repo['repo']}\")\n",
    "            print(f\"   üè∑Ô∏è  Version: {repo.get('rev', 'Not specified')}\")\n",
    "            break\n",
    "\n",
    "if not notebook_config[\"nbstripout_found\"]:\n",
    "    print(\"‚ùå nbstripout hook is NOT configured\")\n",
    "    print(\"   üö® Jupyter notebooks may contain outputs and metadata!\")\n",
    "\n",
    "# Scan for notebook files in the project\n",
    "print(f\"\\nüîç Scanning for Jupyter notebooks:\")\n",
    "notebook_files = []\n",
    "for root, dirs, files in os.walk(\"..\"):\n",
    "    if '.git' in root:\n",
    "        continue\n",
    "    for file in files:\n",
    "        if file.endswith('.ipynb'):\n",
    "            notebook_path = os.path.join(root, file)\n",
    "            rel_path = os.path.relpath(notebook_path, \"..\")\n",
    "            notebook_files.append(rel_path)\n",
    "\n",
    "notebook_config[\"notebook_count\"] = len(notebook_files)\n",
    "\n",
    "if notebook_files:\n",
    "    print(f\"üìä Found {len(notebook_files)} Jupyter notebook(s):\")\n",
    "    for nb_path in notebook_files:\n",
    "        print(f\"   üìÑ {nb_path}\")\n",
    "        \n",
    "        # Check if notebook has outputs\n",
    "        try:\n",
    "            full_path = Path(f\"../{nb_path}\")\n",
    "            with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                nb_content = json.load(f)\n",
    "                \n",
    "            has_outputs = False\n",
    "            output_count = 0\n",
    "            \n",
    "            for cell in nb_content.get('cells', []):\n",
    "                if cell.get('outputs'):\n",
    "                    has_outputs = True\n",
    "                    output_count += len(cell['outputs'])\n",
    "                if cell.get('execution_count'):\n",
    "                    has_outputs = True\n",
    "                    \n",
    "            if has_outputs:\n",
    "                notebook_config[\"notebooks_with_outputs\"].append({\n",
    "                    \"path\": nb_path,\n",
    "                    \"output_count\": output_count\n",
    "                })\n",
    "                print(f\"      ‚ö†Ô∏è  Has {output_count} outputs/execution data\")\n",
    "            else:\n",
    "                print(f\"      ‚úÖ Clean (no outputs)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error reading notebook: {e}\")\n",
    "else:\n",
    "    print(\"   ‚ÑπÔ∏è  No Jupyter notebooks found\")\n",
    "\n",
    "# Evaluate configuration effectiveness\n",
    "print(f\"\\nüìä Notebook Configuration Assessment:\")\n",
    "\n",
    "if notebook_config[\"nbstripout_found\"]:\n",
    "    if len(notebook_config[\"notebooks_with_outputs\"]) == 0:\n",
    "        print(\"üü¢ Excellent: nbstripout is configured and all notebooks are clean\")\n",
    "        recommendation = \"üü¢ Perfect configuration\"\n",
    "    else:\n",
    "        print(f\"üü° Good: nbstripout is configured but {len(notebook_config['notebooks_with_outputs'])} notebook(s) have outputs\")\n",
    "        print(\"   üí° Run nbstripout manually on existing notebooks to clean them\")\n",
    "        recommendation = \"üü° Clean existing notebooks\"\n",
    "else:\n",
    "    if notebook_config[\"notebook_count\"] > 0:\n",
    "        print(\"üî¥ Critical: Notebooks found but nbstripout not configured!\")\n",
    "        recommendation = \"üî¥ Add nbstripout immediately\"\n",
    "    else:\n",
    "        print(\"üü¢ Good: No notebooks found, nbstripout not needed currently\")\n",
    "        recommendation = \"üü¢ Add nbstripout when notebooks are added\"\n",
    "\n",
    "print(f\"\\nüí° Recommendation: {recommendation}\")\n",
    "\n",
    "# Show benefits of nbstripout\n",
    "print(f\"\\nüéØ Benefits of nbstripout:\")\n",
    "print(\"   ‚úÖ Removes sensitive output data\")\n",
    "print(\"   ‚úÖ Reduces repository size\")\n",
    "print(\"   ‚úÖ Cleaner diffs and merges\")\n",
    "print(\"   ‚úÖ Prevents execution metadata conflicts\")\n",
    "print(\"   ‚úÖ Improves collaboration\")\n",
    "\n",
    "if notebook_config[\"notebooks_with_outputs\"]:\n",
    "    total_outputs = sum(nb[\"output_count\"] for nb in notebook_config[\"notebooks_with_outputs\"])\n",
    "    print(f\"\\n‚ö†Ô∏è  Current risk: {total_outputs} outputs across {len(notebook_config['notebooks_with_outputs'])} notebooks\")\n",
    "    print(\"   These could contain sensitive data or large binary content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c742155",
   "metadata": {},
   "source": [
    "## 5. Check Hook Dependencies and Versions\n",
    "\n",
    "Verifying that all hooks are using current versions and checking for potential compatibility issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ff30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hook versions and dependencies\n",
    "version_analysis = {\n",
    "    \"repositories\": [],\n",
    "    \"outdated_count\": 0,\n",
    "    \"security_issues\": [],\n",
    "    \"total_hooks\": 0\n",
    "}\n",
    "\n",
    "print(\"üîç Hook Version Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Known latest versions (as of 2025) - in real scenario, this would be fetched from APIs\n",
    "known_latest = {\n",
    "    \"pre-commit-hooks\": \"v4.6.0\",\n",
    "    \"detect-secrets\": \"v1.4.0\", \n",
    "    \"nbstripout\": \"0.7.1\",\n",
    "    \"black\": \"24.4.2\",\n",
    "    \"flake8\": \"7.0.0\",\n",
    "    \"isort\": \"5.13.2\",\n",
    "    \"mirrors-eslint\": \"v9.5.0\",\n",
    "    \"mirrors-prettier\": \"v4.0.0-alpha.8\",\n",
    "    \"ggshield\": \"v1.25.0\"\n",
    "}\n",
    "\n",
    "for repo_config in precommit_config.get('repos', []):\n",
    "    repo_url = repo_config['repo']\n",
    "    repo_name = repo_url.split('/')[-1] if '/' in repo_url else repo_url\n",
    "    current_version = repo_config.get('rev', 'Not specified')\n",
    "    \n",
    "    # Check if version is specified\n",
    "    if current_version == 'Not specified':\n",
    "        status = \"‚ö†Ô∏è  No version specified\"\n",
    "        recommendation = \"Specify explicit version\"\n",
    "    else:\n",
    "        latest_version = known_latest.get(repo_name, \"Unknown\")\n",
    "        if latest_version != \"Unknown\":\n",
    "            if current_version == latest_version:\n",
    "                status = \"‚úÖ Up to date\"\n",
    "                recommendation = \"Good\"\n",
    "            else:\n",
    "                status = \"üü° Potentially outdated\"\n",
    "                recommendation = f\"Consider updating to {latest_version}\"\n",
    "                version_analysis[\"outdated_count\"] += 1\n",
    "        else:\n",
    "            status = \"‚ùì Version unknown\"\n",
    "            recommendation = \"Manual check required\"\n",
    "    \n",
    "    hook_count = len(repo_config.get('hooks', []))\n",
    "    version_analysis[\"total_hooks\"] += hook_count\n",
    "    \n",
    "    version_analysis[\"repositories\"].append({\n",
    "        \"name\": repo_name,\n",
    "        \"url\": repo_url,\n",
    "        \"current_version\": current_version,\n",
    "        \"status\": status,\n",
    "        \"recommendation\": recommendation,\n",
    "        \"hook_count\": hook_count\n",
    "    })\n",
    "    \n",
    "    print(f\"üì¶ {repo_name}\")\n",
    "    print(f\"   üè∑Ô∏è  Version: {current_version}\")\n",
    "    print(f\"   üìä Status: {status}\")\n",
    "    print(f\"   üîß Hooks: {hook_count}\")\n",
    "    if recommendation != \"Good\":\n",
    "        print(f\"   üí° {recommendation}\")\n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "print(f\"üìä Version Summary:\")\n",
    "print(f\"   üì¶ Total repositories: {len(version_analysis['repositories'])}\")\n",
    "print(f\"   üîß Total hooks: {version_analysis['total_hooks']}\")\n",
    "print(f\"   üü° Potentially outdated: {version_analysis['outdated_count']}\")\n",
    "\n",
    "# Check for security considerations\n",
    "print(f\"\\nüîí Security Analysis:\")\n",
    "\n",
    "security_checks = [\n",
    "    {\n",
    "        \"name\": \"Version pinning\",\n",
    "        \"check\": all(repo[\"current_version\"] != \"Not specified\" for repo in version_analysis[\"repositories\"]),\n",
    "        \"importance\": \"High\",\n",
    "        \"description\": \"All repositories should have pinned versions\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Recent versions\", \n",
    "        \"check\": version_analysis[\"outdated_count\"] <= 1,\n",
    "        \"importance\": \"Medium\",\n",
    "        \"description\": \"Most hooks should be reasonably current\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Security-focused hooks\",\n",
    "        \"check\": any(\"detect\" in repo[\"name\"] or \"ggshield\" in repo[\"name\"] for repo in version_analysis[\"repositories\"]),\n",
    "        \"importance\": \"High\", \n",
    "        \"description\": \"Security scanning hooks should be present\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for check in security_checks:\n",
    "    status = \"‚úÖ\" if check[\"check\"] else \"‚ùå\"\n",
    "    print(f\"   {status} {check['name']} ({check['importance']} priority)\")\n",
    "    print(f\"      {check['description']}\")\n",
    "\n",
    "# Performance considerations\n",
    "print(f\"\\n‚ö° Performance Considerations:\")\n",
    "heavy_hooks = ['ggshield', 'eslint', 'black', 'flake8']\n",
    "configured_heavy = [repo[\"name\"] for repo in version_analysis[\"repositories\"] if repo[\"name\"] in heavy_hooks]\n",
    "\n",
    "if configured_heavy:\n",
    "    print(f\"   üêå Heavy hooks detected: {', '.join(configured_heavy)}\")\n",
    "    print(\"   üí° Consider using 'stages: [manual]' for expensive hooks during development\")\n",
    "else:\n",
    "    print(\"   ‚ö° No particularly heavy hooks detected\")\n",
    "\n",
    "# CI configuration check\n",
    "ci_config = precommit_config.get('ci', {})\n",
    "if ci_config:\n",
    "    print(f\"\\nüöÄ CI Configuration:\")\n",
    "    print(f\"   üîÑ Auto-update: {'‚úÖ' if ci_config.get('autoupdate_schedule') else '‚ùå'}\")\n",
    "    print(f\"   üîß Auto-fix PRs: {'‚úÖ' if ci_config.get('autofix_prs') else '‚ùå'}\")\n",
    "    print(f\"   üìÖ Update schedule: {ci_config.get('autoupdate_schedule', 'Not set')}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå No CI configuration found\")\n",
    "    print(\"   üí° Consider adding CI configuration for automated updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5d4b5",
   "metadata": {},
   "source": [
    "## 6. Validate YAML Structure and Syntax\n",
    "\n",
    "Performing structural validation and checking for proper pre-commit configuration syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate YAML structure and syntax\n",
    "validation_results = {\n",
    "    \"yaml_valid\": False,\n",
    "    \"structure_valid\": False,\n",
    "    \"required_fields\": [],\n",
    "    \"optional_fields\": [],\n",
    "    \"issues\": [],\n",
    "    \"score\": 0\n",
    "}\n",
    "\n",
    "print(\"üîß YAML Structure Validation\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. YAML Syntax Validation\n",
    "try:\n",
    "    # Re-load to ensure it's still valid\n",
    "    with open(config_path, 'r', encoding='utf-8') as file:\n",
    "        config_reloaded = yaml.safe_load(file)\n",
    "    validation_results[\"yaml_valid\"] = True\n",
    "    print(\"‚úÖ YAML syntax is valid\")\n",
    "except yaml.YAMLError as e:\n",
    "    validation_results[\"issues\"].append(f\"YAML syntax error: {e}\")\n",
    "    print(f\"‚ùå YAML syntax error: {e}\")\n",
    "except Exception as e:\n",
    "    validation_results[\"issues\"].append(f\"File error: {e}\")\n",
    "    print(f\"‚ùå File error: {e}\")\n",
    "\n",
    "# 2. Pre-commit Structure Validation\n",
    "if validation_results[\"yaml_valid\"]:\n",
    "    print(f\"\\nüìã Structure Validation:\")\n",
    "    \n",
    "    # Check required top-level fields\n",
    "    required_top_level = ['repos']\n",
    "    optional_top_level = ['ci', 'default_language_version', 'default_stages', 'files', 'exclude']\n",
    "    \n",
    "    for field in required_top_level:\n",
    "        if field in precommit_config:\n",
    "            validation_results[\"required_fields\"].append(field)\n",
    "            print(f\"   ‚úÖ Required field '{field}' present\")\n",
    "        else:\n",
    "            validation_results[\"issues\"].append(f\"Missing required field: {field}\")\n",
    "            print(f\"   ‚ùå Missing required field: {field}\")\n",
    "    \n",
    "    for field in optional_top_level:\n",
    "        if field in precommit_config:\n",
    "            validation_results[\"optional_fields\"].append(field)\n",
    "            print(f\"   ‚ÑπÔ∏è  Optional field '{field}' present\")\n",
    "    \n",
    "    # 3. Repository Structure Validation\n",
    "    print(f\"\\nüì¶ Repository Configuration Validation:\")\n",
    "    \n",
    "    if 'repos' in precommit_config and isinstance(precommit_config['repos'], list):\n",
    "        for i, repo in enumerate(precommit_config['repos']):\n",
    "            print(f\"\\n   Repository {i+1}:\")\n",
    "            \n",
    "            # Check required repo fields\n",
    "            required_repo_fields = ['repo', 'rev', 'hooks']\n",
    "            for field in required_repo_fields:\n",
    "                if field in repo:\n",
    "                    print(f\"      ‚úÖ {field}: {repo[field] if field != 'hooks' else f'{len(repo[field])} hooks'}\")\n",
    "                else:\n",
    "                    issue = f\"Repository {i+1} missing required field: {field}\"\n",
    "                    validation_results[\"issues\"].append(issue)\n",
    "                    print(f\"      ‚ùå Missing {field}\")\n",
    "            \n",
    "            # Validate hooks structure\n",
    "            if 'hooks' in repo and isinstance(repo['hooks'], list):\n",
    "                for j, hook in enumerate(repo['hooks']):\n",
    "                    if 'id' not in hook:\n",
    "                        issue = f\"Repository {i+1}, Hook {j+1} missing required 'id' field\"\n",
    "                        validation_results[\"issues\"].append(issue)\n",
    "                        print(f\"      ‚ùå Hook {j+1} missing 'id'\")\n",
    "                    else:\n",
    "                        print(f\"      ‚úÖ Hook: {hook['id']}\")\n",
    "            else:\n",
    "                issue = f\"Repository {i+1} 'hooks' field must be a list\"\n",
    "                validation_results[\"issues\"].append(issue)\n",
    "                print(f\"      ‚ùå Invalid hooks structure\")\n",
    "    \n",
    "    # 4. CI Configuration Validation (if present)\n",
    "    if 'ci' in precommit_config:\n",
    "        print(f\"\\nüöÄ CI Configuration Validation:\")\n",
    "        ci_config = precommit_config['ci']\n",
    "        \n",
    "        recommended_ci_fields = [\n",
    "            'autofix_commit_msg', 'autofix_prs', 'autoupdate_branch',\n",
    "            'autoupdate_commit_msg', 'autoupdate_schedule'\n",
    "        ]\n",
    "        \n",
    "        for field in recommended_ci_fields:\n",
    "            if field in ci_config:\n",
    "                print(f\"   ‚úÖ {field}: {ci_config[field]}\")\n",
    "            else:\n",
    "                print(f\"   ‚ÑπÔ∏è  Optional CI field '{field}' not configured\")\n",
    "\n",
    "# 5. Best Practices Check\n",
    "print(f\"\\nüéØ Best Practices Validation:\")\n",
    "\n",
    "best_practices = [\n",
    "    {\n",
    "        \"name\": \"Version pinning\",\n",
    "        \"check\": all('rev' in repo and repo['rev'] != 'HEAD' for repo in precommit_config.get('repos', [])),\n",
    "        \"description\": \"All repositories should have pinned versions (not HEAD)\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Hook organization\",\n",
    "        \"check\": len(precommit_config.get('repos', [])) <= 10,\n",
    "        \"description\": \"Reasonable number of repositories (not overwhelming)\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Security hooks present\",\n",
    "        \"check\": any('detect' in str(repo).lower() or 'secret' in str(repo).lower() \n",
    "                    for repo in precommit_config.get('repos', [])),\n",
    "        \"description\": \"Security-related hooks should be configured\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"File processing hooks\",\n",
    "        \"check\": any('nbstripout' in str(repo) or 'trailing-whitespace' in str(repo)\n",
    "                    for repo in precommit_config.get('repos', [])),\n",
    "        \"description\": \"File cleanup hooks should be present\"\n",
    "    }\n",
    "]\n",
    "\n",
    "passed_practices = 0\n",
    "for practice in best_practices:\n",
    "    status = \"‚úÖ\" if practice[\"check\"] else \"‚ö†Ô∏è \"\n",
    "    print(f\"   {status} {practice['name']}\")\n",
    "    print(f\"      {practice['description']}\")\n",
    "    if practice[\"check\"]:\n",
    "        passed_practices += 1\n",
    "\n",
    "validation_results[\"score\"] = (\n",
    "    (1 if validation_results[\"yaml_valid\"] else 0) + \n",
    "    (1 if len(validation_results[\"required_fields\"]) > 0 else 0) +\n",
    "    (1 if len(validation_results[\"issues\"]) == 0 else 0) +\n",
    "    (passed_practices / len(best_practices))\n",
    ") / 4 * 100\n",
    "\n",
    "print(f\"\\nüìä Validation Score: {validation_results['score']:.1f}/100\")\n",
    "\n",
    "if validation_results[\"score\"] >= 90:\n",
    "    print(\"üü¢ Excellent: Configuration follows best practices\")\n",
    "elif validation_results[\"score\"] >= 75:\n",
    "    print(\"üü° Good: Minor improvements possible\")\n",
    "elif validation_results[\"score\"] >= 50:\n",
    "    print(\"üü† Fair: Several issues to address\")\n",
    "else:\n",
    "    print(\"üî¥ Poor: Significant problems with configuration\")\n",
    "\n",
    "if validation_results[\"issues\"]:\n",
    "    print(f\"\\n‚ö†Ô∏è  Issues to address:\")\n",
    "    for issue in validation_results[\"issues\"]:\n",
    "        print(f\"   üî∏ {issue}\")\n",
    "\n",
    "validation_results[\"structure_valid\"] = len(validation_results[\"issues\"]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96ac5f",
   "metadata": {},
   "source": [
    "## 7. Generate Configuration Report\n",
    "\n",
    "Creating a comprehensive report with recommendations, security assessment, and suggested improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive configuration report\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"overall_score\": 0,\n",
    "    \"categories\": {},\n",
    "    \"recommendations\": [],\n",
    "    \"security_rating\": \"\",\n",
    "    \"summary\": \"\"\n",
    "}\n",
    "\n",
    "print(\"üìä COMPREHENSIVE PRE-COMMIT CONFIGURATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üïê Generated: {report['timestamp']}\")\n",
    "print(f\"üìÅ Configuration: .pre-commit-config.yaml\")\n",
    "\n",
    "# Calculate category scores\n",
    "category_scores = {\n",
    "    \"File Size Control\": {\n",
    "        \"score\": 85 if file_size_analysis[\"found\"] and file_size_analysis[\"max_size_kb\"] <= 1000 else \n",
    "                40 if file_size_analysis[\"found\"] else 0,\n",
    "        \"details\": f\"{'‚úÖ' if file_size_analysis['found'] else '‚ùå'} File size limit: {file_size_analysis.get('max_size_kb', 'Not set')} KB\"\n",
    "    },\n",
    "    \"Secret Detection\": {\n",
    "        \"score\": (secret_detection[\"coverage_score\"] / 4) * 100,\n",
    "        \"details\": f\"üîê {secret_detection['coverage_score']}/4 security layers active\"\n",
    "    },\n",
    "    \"Notebook Management\": {\n",
    "        \"score\": 100 if notebook_config[\"nbstripout_found\"] and len(notebook_config[\"notebooks_with_outputs\"]) == 0 else\n",
    "                75 if notebook_config[\"nbstripout_found\"] else\n",
    "                50 if notebook_config[\"notebook_count\"] == 0 else 0,\n",
    "        \"details\": f\"üìì nbstripout: {'‚úÖ' if notebook_config['nbstripout_found'] else '‚ùå'}, Clean notebooks: {notebook_config['notebook_count'] - len(notebook_config['notebooks_with_outputs'])}/{notebook_config['notebook_count']}\"\n",
    "    },\n",
    "    \"Version Management\": {\n",
    "        \"score\": max(0, 100 - (version_analysis[\"outdated_count\"] * 20)),\n",
    "        \"details\": f\"üì¶ {len(version_analysis['repositories']) - version_analysis['outdated_count']}/{len(version_analysis['repositories'])} repos up-to-date\"\n",
    "    },\n",
    "    \"Configuration Quality\": {\n",
    "        \"score\": validation_results[\"score\"],\n",
    "        \"details\": f\"üîß Structure: {'‚úÖ' if validation_results['structure_valid'] else '‚ùå'}, Issues: {len(validation_results['issues'])}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display category breakdown\n",
    "print(f\"\\nüìã CATEGORY ANALYSIS:\")\n",
    "total_score = 0\n",
    "for category, data in category_scores.items():\n",
    "    score = data[\"score\"]\n",
    "    total_score += score\n",
    "    \n",
    "    if score >= 90:\n",
    "        grade = \"üü¢ A\"\n",
    "    elif score >= 80:\n",
    "        grade = \"üü° B\" \n",
    "    elif score >= 70:\n",
    "        grade = \"üü† C\"\n",
    "    elif score >= 60:\n",
    "        grade = \"üî¥ D\"\n",
    "    else:\n",
    "        grade = \"üö® F\"\n",
    "    \n",
    "    print(f\"   {category:<20} {grade} ({score:3.0f}%) - {data['details']}\")\n",
    "    report[\"categories\"][category] = {\"score\": score, \"grade\": grade, \"details\": data[\"details\"]}\n",
    "\n",
    "report[\"overall_score\"] = total_score / len(category_scores)\n",
    "\n",
    "# Overall Assessment\n",
    "print(f\"\\nüéØ OVERALL ASSESSMENT:\")\n",
    "print(f\"   üìä Overall Score: {report['overall_score']:.1f}/100\")\n",
    "\n",
    "if report[\"overall_score\"] >= 90:\n",
    "    overall_grade = \"üü¢ EXCELLENT\"\n",
    "    report[\"summary\"] = \"Outstanding configuration with comprehensive security and quality controls\"\n",
    "elif report[\"overall_score\"] >= 80:\n",
    "    overall_grade = \"üü° GOOD\"\n",
    "    report[\"summary\"] = \"Strong configuration with minor areas for improvement\"\n",
    "elif report[\"overall_score\"] >= 70:\n",
    "    overall_grade = \"üü† FAIR\"\n",
    "    report[\"summary\"] = \"Decent configuration but several important improvements needed\"\n",
    "elif report[\"overall_score\"] >= 60:\n",
    "    overall_grade = \"üî¥ POOR\"\n",
    "    report[\"summary\"] = \"Significant configuration issues that should be addressed\"\n",
    "else:\n",
    "    overall_grade = \"üö® CRITICAL\"\n",
    "    report[\"summary\"] = \"Major configuration problems requiring immediate attention\"\n",
    "\n",
    "print(f\"   üèÜ Grade: {overall_grade}\")\n",
    "print(f\"   üìù {report['summary']}\")\n",
    "\n",
    "# Security Rating\n",
    "security_factors = [\n",
    "    secret_detection[\"coverage_score\"] >= 3,\n",
    "    file_size_analysis[\"found\"],\n",
    "    '.env' in str(precommit_config),  # Check if env files are being handled\n",
    "    validation_results[\"yaml_valid\"]\n",
    "]\n",
    "\n",
    "security_score = sum(security_factors) / len(security_factors) * 100\n",
    "\n",
    "if security_score >= 75:\n",
    "    report[\"security_rating\"] = \"üîí HIGH\"\n",
    "elif security_score >= 50:\n",
    "    report[\"security_rating\"] = \"üü° MEDIUM\"\n",
    "else:\n",
    "    report[\"security_rating\"] = \"üö® LOW\"\n",
    "\n",
    "print(f\"\\nüîí SECURITY RATING: {report['security_rating']} ({security_score:.0f}%)\")\n",
    "\n",
    "# Generate Recommendations\n",
    "print(f\"\\nüí° PRIORITY RECOMMENDATIONS:\")\n",
    "\n",
    "priority_recs = []\n",
    "\n",
    "if not file_size_analysis[\"found\"]:\n",
    "    priority_recs.append(\"üî¥ HIGH: Add check-added-large-files hook immediately\")\n",
    "elif not file_size_analysis[\"max_size_kb\"]:\n",
    "    priority_recs.append(\"üü° MEDIUM: Add explicit --maxkb argument to file size check\")\n",
    "\n",
    "if secret_detection[\"coverage_score\"] < 3:\n",
    "    priority_recs.append(\"üî¥ HIGH: Enhance secret detection with more security layers\")\n",
    "\n",
    "if notebook_config[\"notebook_count\"] > 0 and not notebook_config[\"nbstripout_found\"]:\n",
    "    priority_recs.append(\"üü† MEDIUM: Add nbstripout for Jupyter notebook cleaning\")\n",
    "\n",
    "if len(notebook_config[\"notebooks_with_outputs\"]) > 0:\n",
    "    priority_recs.append(\"üü° LOW: Clean existing notebook outputs manually\")\n",
    "\n",
    "if version_analysis[\"outdated_count\"] > 2:\n",
    "    priority_recs.append(\"üü° MEDIUM: Update outdated hook versions\")\n",
    "\n",
    "if not validation_results[\"structure_valid\"]:\n",
    "    priority_recs.append(\"üî¥ HIGH: Fix YAML configuration issues\")\n",
    "\n",
    "if not priority_recs:\n",
    "    priority_recs.append(\"üü¢ Configuration is excellent - no critical issues!\")\n",
    "\n",
    "for i, rec in enumerate(priority_recs[:5], 1):  # Top 5 recommendations\n",
    "    print(f\"   {i}. {rec}\")\n",
    "    report[\"recommendations\"].append(rec)\n",
    "\n",
    "# Implementation Steps\n",
    "print(f\"\\nüõ†Ô∏è  NEXT STEPS:\")\n",
    "print(\"   1. Address HIGH priority recommendations first\")\n",
    "print(\"   2. Test configuration with: `pre-commit run --all-files`\")\n",
    "print(\"   3. Install hooks: `pre-commit install`\")\n",
    "print(\"   4. Monitor performance and adjust as needed\")\n",
    "print(\"   5. Schedule regular configuration reviews\")\n",
    "\n",
    "# Save report summary\n",
    "print(f\"\\nüíæ Report complete! Key metrics:\")\n",
    "print(f\"   ‚Ä¢ {len(precommit_config.get('repos', []))} repositories configured\")\n",
    "print(f\"   ‚Ä¢ {version_analysis['total_hooks']} total hooks\")\n",
    "print(f\"   ‚Ä¢ {secret_detection['coverage_score']}/4 security layers\")\n",
    "print(f\"   ‚Ä¢ {len(priority_recs)} recommendations\")\n",
    "\n",
    "print(f\"\\nüéâ Pre-commit configuration evaluation complete!\")\n",
    "print(\"   Use this analysis to improve your repository's quality and security.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
